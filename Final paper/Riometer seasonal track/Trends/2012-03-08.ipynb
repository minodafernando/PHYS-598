{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2988cf61-c13b-49a3-8137-91d7485cdaac",
   "metadata": {},
   "source": [
    "## Number of hEs points per hour as a function of average/peak riometer absorption in that hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b49b-d5a6-4d51-a2f1-4de212bd7e8e",
   "metadata": {},
   "source": [
    "#### 1) Get average riometer absorption per hour for the days:\n",
    "##### 1.  2012-01-23\n",
    "##### 2.  2012-02-07\n",
    "##### 3.  2012-03-01\n",
    "##### 4.  2012-03-07\n",
    "##### 5.  2012-03-08\n",
    "##### 6.  2012-03-13\n",
    "##### 7.  2012-03-15\n",
    "##### 8.  2012-04-03\n",
    "##### 9.  2012-04-25\n",
    "##### 10. 2012-07-06\n",
    "##### 11. 2012-11-01\n",
    "##### 12. 2012-11-07\n",
    "\n",
    "#### 2) Get hEs points per hour for those days\n",
    "#### 3) Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e559e64-1103-4837-b18f-92fbcd964569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) average rio absorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597f4473-c7c2-4558-b36d-d6de0453d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import urllib.request\n",
    "\n",
    "# define riometer readfile function\n",
    "def rio_readfile(url):\n",
    "\n",
    "    # Define lists\n",
    "    #date = [] #do i even need the date cause it's the same year?\n",
    "    time = []\n",
    "    absorption = []\n",
    "    raw_sig = []\n",
    "\n",
    "    # Define filename\n",
    "    #filename = \"RD 2012-03-03.txt\"\n",
    "\n",
    "    # open file to read\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html_response = response.read()\n",
    "    encoding = response.headers.get_content_charset(\"utf-8\")\n",
    "    fp = html_response.decode(encoding)\n",
    "\n",
    "    # define new list sanitized_data\n",
    "    # entry = [] list defined later, append datetime, absp, raw sig to it\n",
    "    # later append entry to sanitized_data so it will be lists within a list\n",
    "    sanitized_data = []\n",
    "    \n",
    "    for line in fp.splitlines():\n",
    "        #print(line)\n",
    "        #print(str(line))\n",
    "    \n",
    "        # skip comments\n",
    "        if line[0] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            # strip line\n",
    "            line_strip = line.strip()\n",
    "            # split lines into lists\n",
    "            line_split = line.split()\n",
    "            #print(line_split[1])\n",
    "\n",
    "            # Define datetime format for date and time\n",
    "            \n",
    "            format = \"%d%m%Y%H:%M:%S\"\n",
    "            \n",
    "            # split column 0 to month, date, year and make one row\n",
    "            month = str(line_split[0].split(\"/\")[1])\n",
    "            day = str(line_split[0].split(\"/\")[0])\n",
    "            year = \"20\" + str(line_split[0].split(\"/\")[2])\n",
    "                      \n",
    "            # change this to dd mm yy!!!!!!!!!!!\n",
    "            full_date = day + month + year + str(line_split[1])\n",
    "            \n",
    "            # Try-except to see if can convert to datetime\n",
    "            try:\n",
    "                res = bool(datetime.datetime.strptime(full_date, format))\n",
    "                this_time = datetime.datetime.strptime(full_date, format)\n",
    "\n",
    "                # Get rid of negative absorption values\n",
    "                if float(line_split[2]) < 0:\n",
    "                    continue\n",
    "                # append time to array\n",
    "                time.append(this_time)\n",
    "                # append absorption to array\n",
    "                absorption.append(float(line_split[2]))\n",
    "                # append raw signals to array\n",
    "      \n",
    "                raw_sig.append(line_split[3])\n",
    "\n",
    "                # define new list \n",
    "                entry = []\n",
    "                entry.append(this_time)\n",
    "                entry.append(line_split[2])\n",
    "                entry.append(line_split[3])\n",
    "                \n",
    "                sanitized_data.append(entry)\n",
    "                    \n",
    "            except ValueError:\n",
    "                res = False\n",
    "\n",
    "    #return sanitized_data\n",
    "    return sanitized_data, time, absorption, raw_sig\n",
    "    #return absorption\n",
    "    #return raw_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef06eabe-5f8a-4627-b029-eebbd6f829b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import stuff\n",
    "import numpy as np\n",
    "\n",
    "def ionosonde_plotter(f):\n",
    "    # Define timestamp array\n",
    "    timestamp_full = []\n",
    "\n",
    "    # Minimum virtual height of E trace\n",
    "    hE = []\n",
    "    timestamp_hE = []\n",
    "    # Minimum virtual height of Es trace\n",
    "    hEs = []\n",
    "    timestamp_hEs = []\n",
    "\n",
    "    # Define CS array\n",
    "    CS = []\n",
    "\n",
    "    # E layer critical frequency\n",
    "    foE =[]\n",
    "    timestamp_foE = []\n",
    "    # Es layer critical frequency\n",
    "    foEs = []\n",
    "    timestamp_foEs = []\n",
    "\n",
    "\n",
    "    # Define filename\n",
    "    filename = f + \".txt\"\n",
    "\n",
    "    # define indices for each parameter of file\n",
    "    time_idx = 0\n",
    "    CS_idx = 1\n",
    "    foEs_idx = 2\n",
    "    foE_idx = 4\n",
    "    hE_idx = 6\n",
    "    hEs_idx = 8\n",
    "\n",
    "    # Define format for datetime\n",
    "    format = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "\n",
    "    # Open file - read\n",
    "    fp = open(filename, 'r')\n",
    "    # Read every line in file\n",
    "    for line in fp:\n",
    "    # Skip comments\n",
    "        if line[0] == \"#\":\n",
    "            continue\n",
    "    # Strip lines\n",
    "        else:\n",
    "            line_strip = line.strip()\n",
    "    # Split lines into lists\n",
    "            line_split = line.split()\n",
    "\n",
    "            foE_str = line_split[foE_idx]\n",
    "            foEs_str = line_split[foEs_idx]\n",
    "            hE_str = line_split[hE_idx]\n",
    "            hEs_str = line_split[hEs_idx]\n",
    "\n",
    "            timestamp_full.append(datetime.datetime.strptime(line_split[time_idx], format))\n",
    "\n",
    "            # Check if can convert foE to float\n",
    "            try:\n",
    "                foE_float = float(foE_str)\n",
    "                # If successful, append to the array\n",
    "                foE.append(foE_float)\n",
    "                # Extract timestamp and append to the array\n",
    "                timestamp_str = line_split[time_idx]\n",
    "                timestamp_foE.append(datetime.datetime.strptime(timestamp_str, format))\n",
    "            except ValueError:\n",
    "                # If the conversion fails, ignore the line\n",
    "                pass\n",
    "\n",
    "            # Check if can convert foEs to float\n",
    "            try:\n",
    "                foEs_float = float(foEs_str)\n",
    "                # If successful, append to the array\n",
    "                foEs.append(foEs_float)\n",
    "                # Extract timestamp and append to the array\n",
    "                timestamp_str = line_split[time_idx]\n",
    "                timestamp_foEs.append(datetime.datetime.strptime(timestamp_str, format))\n",
    "            except ValueError:\n",
    "                # If the conversion fails, ignore the line\n",
    "                pass\n",
    "\n",
    "            # Check if hE can convert to float\n",
    "            try:\n",
    "                hE_float = float(hE_str)\n",
    "                # If successful, append to the array\n",
    "                hE.append(hE_float)\n",
    "                # Extract timestamp and append to the array\n",
    "                timestamp_strhE = line_split[time_idx]\n",
    "                timestamp_hE.append(datetime.datetime.strptime(timestamp_strhE, format))\n",
    "            except ValueError:\n",
    "                # If the conversion fails, ignore the line\n",
    "                pass\n",
    "\n",
    "            # Check if hEs can convert to float\n",
    "            try:\n",
    "                hEs_float = float(hEs_str)\n",
    "                # If successful, append to the array\n",
    "                hEs.append(hEs_float)\n",
    "                # Extract timestamp and append to the array\n",
    "                timestamp_strhEs = line_split[time_idx]\n",
    "                timestamp_hEs.append(datetime.datetime.strptime(timestamp_strhEs, format))\n",
    "            except ValueError:\n",
    "                # If the conversion fails, ignore the line\n",
    "                pass\n",
    "\n",
    "    return timestamp_foEs, foEs, timestamp_hEs, hEs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca080c5-5d43-4698-9f3b-84ef32de1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call rio readfile on 2012/03/08 riometer file\n",
    "url = \"https://data.phys.ucalgary.ca/sort_by_project/GO-Canada/GO-Rio/txt/2012/03/08/norstar_k2_rio-daws_20120308_v01.txt\"\n",
    "\n",
    "sanitized_data, time, absorption, raw_sig = rio_readfile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20473e4-6490-4b19-899d-7367049f2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ionosonde readfile on 2012-03-08\n",
    "f = \"2012-03-08\"\n",
    "\n",
    "timestamp_foEs, foEs, timestamp_hEs, hEs = ionosonde_plotter(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a114fd73-8b95-4058-8689-16e748789118",
   "metadata": {},
   "source": [
    "#### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f301c5cf-ff6d-4a7a-85b3-701f41641297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.287029166666667\n"
     ]
    }
   ],
   "source": [
    "import statistics as stats\n",
    "\n",
    "hour = 2\n",
    "abs_values = []\n",
    "\n",
    "for idx, list in enumerate(sanitized_data):\n",
    "    time_needed = list[0]\n",
    "    t_hour = int(time_needed.hour)\n",
    "    if t_hour == hour:\n",
    "        abs_needed = float(list[1])\n",
    "        abs_values.append(abs_needed)\n",
    "        avg = stats.mean(abs_values)\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32077a1-34aa-4e90-9fc7-e927523cda23",
   "metadata": {},
   "source": [
    "### Average absorption values for each hour of one UT day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a79855-052b-4dea-8a51-97d5bc5300b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# find avg of that list\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabs_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# append that avg to avg_abs list\u001b[39;00m\n\u001b[0;32m     30\u001b[0m avg_abs\u001b[38;5;241m.\u001b[39mappend(avg)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\statistics.py:484\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(data):\n\u001b[0;32m    469\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the sample arithmetic mean of data.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    >>> mean([1, 2, 3, 4, 4])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    If ``data`` is empty, StatisticsError will be raised.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     T, total, n \u001b[38;5;241m=\u001b[39m \u001b[43m_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m StatisticsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean requires at least one data point\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\statistics.py:193\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m typ, values \u001b[38;5;129;01min\u001b[39;00m groupby(data, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m    192\u001b[0m     types_add(typ)\n\u001b[1;32m--> 193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_exact_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartials\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpartials_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\statistics.py:287\u001b[0m, in \u001b[0;36m_exact_ratio\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    283\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know how to coerce \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg \u001b[38;5;241m%\u001b[39m (T\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, S\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_exact_ratio\u001b[39m(x):\n\u001b[0;32m    288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return Real number x to exact (numerator, denominator) pair.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    >>> _exact_ratio(0.25)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    x is expected to be an int, Fraction, Decimal or float.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m# XXX We should revisit whether using fractions to accumulate exact\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;66;03m# ratios is the right way to go.\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;66;03m# This doesn't seem to have been problem in practice, but it is a\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# potential pitfall.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hours = []\n",
    "for i in range(0,24):\n",
    "    hours.append(i)\n",
    "\n",
    "# list to store average absorption values for each hour of the day (length = 24)\n",
    "avg_abs = []\n",
    "\n",
    "# go through all 24 hours (from 0-23)\n",
    "for idx, list in enumerate(sanitized_data):\n",
    "    # go through each list in san_data\n",
    "    for hour in hours:\n",
    "        # get timestamp from list\n",
    "        time_needed = list[0]\n",
    "        # convert it to int hour\n",
    "        t_hour = int(time_needed.hour)\n",
    "        # define list to store indices of correct lists for that hour\n",
    "        index_hour_list = []\n",
    "        # if the hours match\n",
    "        if t_hour == hour:\n",
    "            index_list.append(idx)\n",
    "\n",
    "        for i in index_list:\n",
    "            needed_list = sanitized_data[i]\n",
    "            # try except on absorption vals to float\n",
    "            try:\n",
    "                # get the absorption values and convert to float\n",
    "                abs_needed = float(needed_list[1])\n",
    "                # append the absorption needed to abs_values list\n",
    "                abs_values.append(abs_needed)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        # find avg of that list\n",
    "        avg = stats.mean(abs_values)\n",
    "    # append that avg to avg_abs list\n",
    "    avg_abs.append(avg)\n",
    "\n",
    "print(avg_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18b26a-e4bf-472c-92d5-ab640f1dad45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
